{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "source": [
    "# NLP Tweets for Natural Disasters\n",
    "#### Github link: https://github.com/wiwi9262/tweet_distasters\n",
    "## Overview\n",
    "* We have a large corpus of tweets\n",
    "* We would like to know which of these tweets are related to natural disasters\n",
    "* There are thousands of unique words that we need to look at as part of our analysis\n",
    "* We plan to use term frequency inverse document frequency to build our initial features\n",
    "* This method is not perfect, but it provides more than a simple bag of words approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "#import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.classify import SklearnClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need the stopwords lists so we can remove extremely common words that will not help our analysis\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfTweets = pd.read_csv(\"../input/nlp-getting-started/train.csv\")\n",
    "dfTweetsTest = pd.read_csv(\"../input/nlp-getting-started/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see a lot of NaN in keyword and locatin\n",
    "# We will explore further but it is likely that we will not be able to use these\n",
    "dfTweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTweetsTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dfTweets.info()\n",
    "# We can see that there are more than 2000 null locations and about 60 null keywords\n",
    "# Probably too many null locations to be useful, unless the ones that are there are really impactful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "dfTweetsTest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatalities               45\n",
       "deluge                   42\n",
       "armageddon               42\n",
       "sinking                  41\n",
       "damage                   41\n",
       "                         ..\n",
       "forest%20fire            19\n",
       "epicentre                12\n",
       "threat                   11\n",
       "inundation               10\n",
       "radiation%20emergency     9\n",
       "Name: keyword, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTweets['keyword'].value_counts()\n",
    "# There are 221 unique keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA                    104\n",
       "New York                71\n",
       "United States           50\n",
       "London                  45\n",
       "Canada                  29\n",
       "                      ... \n",
       "MontrÌ©al, QuÌ©bec       1\n",
       "Montreal                 1\n",
       "ÌÏT: 6.4682,3.18287      1\n",
       "Live4Heed??              1\n",
       "Lincoln                  1\n",
       "Name: location, Length: 3341, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTweets['location'].value_counts()\n",
    "# This is a mess. Just drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Our Deeds are the Reason of this  earthquake M...\n",
       "1                  Forest fire near La Ronge Sask  Canada\n",
       "2       All residents asked to  shelter in place  are ...\n",
       "3              people receive  wildfires evacuation or...\n",
       "4       Just got sent this photo from Ruby  Alaska as ...\n",
       "                              ...                        \n",
       "7608    Two giant cranes holding a bridge collapse int...\n",
       "7609     aria ahrary  TheTawniest The out of control w...\n",
       "7610          M            UTC   km S of Volcano Hawaii  \n",
       "7611    Police investigating after an e bike collided ...\n",
       "7612    The Latest  More Homes Razed by Northern Calif...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove URLs\n",
    "dfTweets['text'] = dfTweets['text'].replace(r'http\\S+', '', regex=True)\n",
    "\n",
    "# Make this simple and remove any character that is not in range of English letters\n",
    "# There are emoji and punctuation that we cant reasonably use. just clear it all out\n",
    "dfTweets['text'] = dfTweets['text'].replace(r'[^A-Za-z]', ' ', regex=True)\n",
    "dfTweets['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Our Deeds are the Reason of this  earthquake M...\n",
       "1                  Forest fire near La Ronge Sask  Canada\n",
       "2       All residents asked to  shelter in place  are ...\n",
       "3              people receive  wildfires evacuation or...\n",
       "4       Just got sent this photo from Ruby  Alaska as ...\n",
       "                              ...                        \n",
       "6957    a siren just went off and it wasn t the Forney...\n",
       "6958    Officials say a quarantine is in place at an A...\n",
       "6959     WorldNews Fallen powerlines on G link tram  U...\n",
       "6960    on the flip side I m at Walmart and there is a...\n",
       "6961    Suicide bomber kills    in Saudi security site...\n",
       "Name: text, Length: 6962, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Duplicates\n",
    "# There are a lot of records that have duplicate text\n",
    "# I am dropping the duplicates so they dont lead to overtraining issues\n",
    "dfTweets.drop_duplicates(subset=['text'], inplace=True)\n",
    "dfTweets.reset_index(inplace=True)\n",
    "dfTweets['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "* There are a lot of unique words so we will limit what we will illustrate\n",
    "* We explore the data as we extract features\n",
    "* Additional Visualizations are included after feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=dfTweets, x=\"target\",bins=2).set(title='Training Label␣Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aaaa', 'aaaaaaallll', ..., 'zurich', 'zxathetis', 'zzzz'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Extraction\n",
    "# We will use TD-IDF\n",
    "\n",
    "# https://www.kaggle.com/code/amar09/nltk-feature-extraction-and-sentiment-analysis/notebook\n",
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords_set)\n",
    "trans = vectorizer.fit_transform(dfTweets['text'])\n",
    "vectorizer.get_feature_names_out()\n",
    "\n",
    "# Some of these are clearly the same word but I am not going to word stem it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6962, 16050)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfSparse = pd.DataFrame(pd.DataFrame.sparse.from_spmatrix(trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfeature_array = np.array(vectorizer.get_feature_names())\\ntfidf_sorting = np.argsort(trans.toarray()).flatten()[::-1]\\nn = 5\\ntop_n = feature_array[tfidf_sorting][:n]\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at top n words \n",
    "# Could not run this due to memory constraints\n",
    "# The plan was to get the top features(words) then create visualizations showing proportion of those words \n",
    "#     for each label\n",
    "### Unfortunately, the code gave error that it couldn't allocate the memory required\n",
    "\"\"\"\n",
    "feature_array = np.array(vectorizer.get_feature_names())\n",
    "tfidf_sorting = np.argsort(trans.toarray()).flatten()[::-1]\n",
    "n = 5\n",
    "top_n = feature_array[tfidf_sorting][:n]\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1\n",
    "* We originally created a RNN for the first model\n",
    "* It was taking way to long to train\n",
    "* When we attempted a basic back propagation neural network, we saw that it had good results out of the box "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train,  x_test, y_train, y_test = train_test_split(dfSparse,dfTweets['target'],test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = x_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 18:31:39.972789: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model1 = models.Sequential()\n",
    "model1.add(layers.Dense(32, activation=\"relu\"))\n",
    "model1.add(layers.Dense(1, activation=\"sigmoid\")) \n",
    "model1.compile(optimizer='adam',\n",
    "               loss=\"binary_crossentropy\",\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                513632    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 513,665\n",
      "Trainable params: 513,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.build(input_shape=(None,shape))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 1s 8ms/step - loss: 0.0470 - accuracy: 0.9896 - val_loss: 0.5661 - val_accuracy: 0.7645\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.0384 - accuracy: 0.9914 - val_loss: 0.5846 - val_accuracy: 0.7717\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.0324 - accuracy: 0.9930 - val_loss: 0.6107 - val_accuracy: 0.7609\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7febc47f15d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "es = EarlyStopping(monitor='val_loss', mode='auto', patience=2, verbose=1)\n",
    "model1.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), \n",
    "    batch_size=batch_size, epochs=20,\n",
    "    callbacks=[es]\n",
    ")\n",
    "# Got memory error and had to change memory of VM to run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test It\n",
    "\n",
    "# Make this stuff into a function\n",
    "# Remove URLs\n",
    "dfTweetsTest['text'] = dfTweetsTest['text'].replace(r'http\\S+', '', regex=True)\n",
    "# Make this simple and remove any character that is not in range of English letters\n",
    "dfTweetsTest['text'] = dfTweetsTest['text'].replace(r'[^A-Za-z]', ' ', regex=True)\n",
    "trans_test = vectorizer.transform(dfTweetsTest['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSparseTest = pd.DataFrame(pd.DataFrame.sparse.from_spmatrix(trans_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(dfSparseTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_reset = dfTweetsTest['id'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_reset['target'] = y_pred.round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_reset = index_reset.drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_reset.to_csv(\"test_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2\n",
    "* There are a lot of features and things are sparse\n",
    "* We want to see if PCA will work to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with dfSparse and PCA it\n",
    "dfScaled = StandardScaler().fit_transform(dfSparse.sparse.to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricipalComponents = pca.fit_transform(dfScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPCA = pd.DataFrame(data = pricipalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5074</th>\n",
       "      <th>5075</th>\n",
       "      <th>5076</th>\n",
       "      <th>5077</th>\n",
       "      <th>5078</th>\n",
       "      <th>5079</th>\n",
       "      <th>5080</th>\n",
       "      <th>5081</th>\n",
       "      <th>5082</th>\n",
       "      <th>5083</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.078239</td>\n",
       "      <td>-0.059097</td>\n",
       "      <td>-0.088612</td>\n",
       "      <td>-0.064248</td>\n",
       "      <td>-0.077703</td>\n",
       "      <td>-0.071834</td>\n",
       "      <td>-0.091831</td>\n",
       "      <td>-0.105413</td>\n",
       "      <td>-0.030995</td>\n",
       "      <td>0.209931</td>\n",
       "      <td>...</td>\n",
       "      <td>3.573027</td>\n",
       "      <td>3.527792</td>\n",
       "      <td>-2.674477</td>\n",
       "      <td>-1.939103</td>\n",
       "      <td>-0.154365</td>\n",
       "      <td>-4.237834</td>\n",
       "      <td>5.724807</td>\n",
       "      <td>-2.733402</td>\n",
       "      <td>0.637556</td>\n",
       "      <td>4.372344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.087677</td>\n",
       "      <td>-0.097656</td>\n",
       "      <td>-0.107262</td>\n",
       "      <td>-0.053224</td>\n",
       "      <td>-0.068927</td>\n",
       "      <td>-0.064815</td>\n",
       "      <td>-0.108207</td>\n",
       "      <td>-0.094312</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>-0.082191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122445</td>\n",
       "      <td>0.217479</td>\n",
       "      <td>-0.397394</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>-0.301586</td>\n",
       "      <td>0.213998</td>\n",
       "      <td>-0.019760</td>\n",
       "      <td>-0.088871</td>\n",
       "      <td>-0.143952</td>\n",
       "      <td>-0.031781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.097218</td>\n",
       "      <td>-0.117339</td>\n",
       "      <td>-0.110340</td>\n",
       "      <td>-0.077047</td>\n",
       "      <td>-0.075919</td>\n",
       "      <td>-0.083193</td>\n",
       "      <td>-0.141215</td>\n",
       "      <td>-0.127405</td>\n",
       "      <td>-0.050976</td>\n",
       "      <td>-0.023662</td>\n",
       "      <td>...</td>\n",
       "      <td>1.950131</td>\n",
       "      <td>1.558722</td>\n",
       "      <td>-1.188495</td>\n",
       "      <td>-1.192894</td>\n",
       "      <td>-0.664467</td>\n",
       "      <td>-1.828405</td>\n",
       "      <td>0.771438</td>\n",
       "      <td>-0.950145</td>\n",
       "      <td>0.831304</td>\n",
       "      <td>-0.841750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.074988</td>\n",
       "      <td>-0.110750</td>\n",
       "      <td>-0.113140</td>\n",
       "      <td>-0.042910</td>\n",
       "      <td>-0.070116</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>-0.091503</td>\n",
       "      <td>-0.106347</td>\n",
       "      <td>-0.023609</td>\n",
       "      <td>-0.094358</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266367</td>\n",
       "      <td>-0.261358</td>\n",
       "      <td>-0.327892</td>\n",
       "      <td>-0.746833</td>\n",
       "      <td>-0.015095</td>\n",
       "      <td>0.221197</td>\n",
       "      <td>-0.493712</td>\n",
       "      <td>-0.260344</td>\n",
       "      <td>0.641124</td>\n",
       "      <td>-0.353278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.085266</td>\n",
       "      <td>-0.114545</td>\n",
       "      <td>-0.115498</td>\n",
       "      <td>-0.060910</td>\n",
       "      <td>-0.077873</td>\n",
       "      <td>-0.023808</td>\n",
       "      <td>-0.089835</td>\n",
       "      <td>-0.075962</td>\n",
       "      <td>-0.038396</td>\n",
       "      <td>-0.088510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197062</td>\n",
       "      <td>0.391773</td>\n",
       "      <td>-0.187452</td>\n",
       "      <td>0.578017</td>\n",
       "      <td>0.528905</td>\n",
       "      <td>0.216513</td>\n",
       "      <td>-0.362800</td>\n",
       "      <td>-0.195314</td>\n",
       "      <td>0.026133</td>\n",
       "      <td>-0.544563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6957</th>\n",
       "      <td>-0.079908</td>\n",
       "      <td>-0.119963</td>\n",
       "      <td>-0.103486</td>\n",
       "      <td>-0.056947</td>\n",
       "      <td>-0.063933</td>\n",
       "      <td>-0.072289</td>\n",
       "      <td>0.008172</td>\n",
       "      <td>0.893871</td>\n",
       "      <td>-0.522908</td>\n",
       "      <td>0.069312</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.239300</td>\n",
       "      <td>0.099060</td>\n",
       "      <td>-3.516804</td>\n",
       "      <td>-3.841305</td>\n",
       "      <td>-4.814662</td>\n",
       "      <td>3.082075</td>\n",
       "      <td>-3.621484</td>\n",
       "      <td>-3.364453</td>\n",
       "      <td>-3.086844</td>\n",
       "      <td>1.070920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6958</th>\n",
       "      <td>-0.116479</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.146840</td>\n",
       "      <td>-0.091773</td>\n",
       "      <td>-0.080399</td>\n",
       "      <td>-0.114345</td>\n",
       "      <td>-0.122161</td>\n",
       "      <td>-0.133403</td>\n",
       "      <td>-0.038602</td>\n",
       "      <td>-0.027939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106050</td>\n",
       "      <td>0.056327</td>\n",
       "      <td>0.210149</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>0.117060</td>\n",
       "      <td>0.161468</td>\n",
       "      <td>-0.046727</td>\n",
       "      <td>-0.080902</td>\n",
       "      <td>0.143639</td>\n",
       "      <td>0.171874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6959</th>\n",
       "      <td>-0.120347</td>\n",
       "      <td>-0.149664</td>\n",
       "      <td>-0.157010</td>\n",
       "      <td>-0.095254</td>\n",
       "      <td>-0.101343</td>\n",
       "      <td>0.014169</td>\n",
       "      <td>-0.130838</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.009812</td>\n",
       "      <td>-0.025372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025185</td>\n",
       "      <td>-0.234559</td>\n",
       "      <td>-0.575541</td>\n",
       "      <td>-0.175855</td>\n",
       "      <td>-0.020906</td>\n",
       "      <td>0.110054</td>\n",
       "      <td>-0.416302</td>\n",
       "      <td>0.015159</td>\n",
       "      <td>-0.716243</td>\n",
       "      <td>-0.012042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6960</th>\n",
       "      <td>-0.046046</td>\n",
       "      <td>-0.106149</td>\n",
       "      <td>0.008219</td>\n",
       "      <td>-0.061119</td>\n",
       "      <td>-0.078789</td>\n",
       "      <td>-0.051406</td>\n",
       "      <td>0.830471</td>\n",
       "      <td>-0.054644</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>-0.067867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.383817</td>\n",
       "      <td>-2.121286</td>\n",
       "      <td>0.427881</td>\n",
       "      <td>1.077513</td>\n",
       "      <td>-0.598742</td>\n",
       "      <td>-1.132784</td>\n",
       "      <td>0.579136</td>\n",
       "      <td>-1.010110</td>\n",
       "      <td>0.758766</td>\n",
       "      <td>0.114784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6961</th>\n",
       "      <td>-0.126634</td>\n",
       "      <td>-0.065979</td>\n",
       "      <td>-0.098844</td>\n",
       "      <td>-0.053080</td>\n",
       "      <td>-0.114897</td>\n",
       "      <td>-0.050133</td>\n",
       "      <td>-0.171578</td>\n",
       "      <td>-0.199000</td>\n",
       "      <td>-0.051251</td>\n",
       "      <td>0.171169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398769</td>\n",
       "      <td>-0.063645</td>\n",
       "      <td>-0.056966</td>\n",
       "      <td>0.248449</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>-0.338356</td>\n",
       "      <td>0.200416</td>\n",
       "      <td>-0.036741</td>\n",
       "      <td>-0.202559</td>\n",
       "      <td>-0.527217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6962 rows × 5084 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0    -0.078239 -0.059097 -0.088612 -0.064248 -0.077703 -0.071834 -0.091831   \n",
       "1    -0.087677 -0.097656 -0.107262 -0.053224 -0.068927 -0.064815 -0.108207   \n",
       "2    -0.097218 -0.117339 -0.110340 -0.077047 -0.075919 -0.083193 -0.141215   \n",
       "3    -0.074988 -0.110750 -0.113140 -0.042910 -0.070116 -0.000215 -0.091503   \n",
       "4    -0.085266 -0.114545 -0.115498 -0.060910 -0.077873 -0.023808 -0.089835   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6957 -0.079908 -0.119963 -0.103486 -0.056947 -0.063933 -0.072289  0.008172   \n",
       "6958 -0.116479 -0.129516 -0.146840 -0.091773 -0.080399 -0.114345 -0.122161   \n",
       "6959 -0.120347 -0.149664 -0.157010 -0.095254 -0.101343  0.014169 -0.130838   \n",
       "6960 -0.046046 -0.106149  0.008219 -0.061119 -0.078789 -0.051406  0.830471   \n",
       "6961 -0.126634 -0.065979 -0.098844 -0.053080 -0.114897 -0.050133 -0.171578   \n",
       "\n",
       "          7         8         9     ...      5074      5075      5076  \\\n",
       "0    -0.105413 -0.030995  0.209931  ...  3.573027  3.527792 -2.674477   \n",
       "1    -0.094312  0.011191 -0.082191  ...  0.122445  0.217479 -0.397394   \n",
       "2    -0.127405 -0.050976 -0.023662  ...  1.950131  1.558722 -1.188495   \n",
       "3    -0.106347 -0.023609 -0.094358  ... -0.266367 -0.261358 -0.327892   \n",
       "4    -0.075962 -0.038396 -0.088510  ...  0.197062  0.391773 -0.187452   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6957  0.893871 -0.522908  0.069312  ... -1.239300  0.099060 -3.516804   \n",
       "6958 -0.133403 -0.038602 -0.027939  ...  0.106050  0.056327  0.210149   \n",
       "6959 -0.109889 -0.009812 -0.025372  ... -0.025185 -0.234559 -0.575541   \n",
       "6960 -0.054644 -0.000386 -0.067867  ... -0.383817 -2.121286  0.427881   \n",
       "6961 -0.199000 -0.051251  0.171169  ...  0.398769 -0.063645 -0.056966   \n",
       "\n",
       "          5077      5078      5079      5080      5081      5082      5083  \n",
       "0    -1.939103 -0.154365 -4.237834  5.724807 -2.733402  0.637556  4.372344  \n",
       "1     0.016972 -0.301586  0.213998 -0.019760 -0.088871 -0.143952 -0.031781  \n",
       "2    -1.192894 -0.664467 -1.828405  0.771438 -0.950145  0.831304 -0.841750  \n",
       "3    -0.746833 -0.015095  0.221197 -0.493712 -0.260344  0.641124 -0.353278  \n",
       "4     0.578017  0.528905  0.216513 -0.362800 -0.195314  0.026133 -0.544563  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6957 -3.841305 -4.814662  3.082075 -3.621484 -3.364453 -3.086844  1.070920  \n",
       "6958  0.011611  0.117060  0.161468 -0.046727 -0.080902  0.143639  0.171874  \n",
       "6959 -0.175855 -0.020906  0.110054 -0.416302  0.015159 -0.716243 -0.012042  \n",
       "6960  1.077513 -0.598742 -1.132784  0.579136 -1.010110  0.758766  0.114784  \n",
       "6961  0.248449  0.054900 -0.338356  0.200416 -0.036741 -0.202559 -0.527217  \n",
       "\n",
       "[6962 rows x 5084 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPCA\n",
    "# PCA did not reduce the number of feature by as much as I was hoping with an explained variance setting of 95%\n",
    "# We got reduce to about a third but I was hoping for more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,  x_test, y_train, y_test = train_test_split(dfPCA,dfTweets['target'],test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Dense(32, activation=\"relu\"))\n",
    "model2.add(layers.Dense(1, activation=\"sigmoid\")) \n",
    "model2.compile(optimizer='adam',\n",
    "               loss=\"binary_crossentropy\",\n",
    "               metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 32)                162720    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 162,753\n",
      "Trainable params: 162,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shape = x_test.shape[1]\n",
    "model2.build(input_shape=(None,shape))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.8981 - accuracy: 0.6190 - val_loss: 0.8113 - val_accuracy: 0.6834\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1083 - accuracy: 0.9646 - val_loss: 0.8298 - val_accuracy: 0.6834\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.0749 - accuracy: 0.9776 - val_loss: 0.8563 - val_accuracy: 0.6906\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feaf5b319d0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "es = EarlyStopping(monitor='val_loss', mode='auto', patience=2, verbose=1)\n",
    "model2.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), \n",
    "    batch_size=batch_size, epochs=20,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The validation accuracy was not good. It seems that this overtrains too quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3\n",
    "* The previous model showed poor results because it quickly overtrained\n",
    "* We will add a dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 32)                162720    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 162,753\n",
      "Trainable params: 162,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(layers.Dense(32, activation=\"relu\"))\n",
    "model3.add(layers.Dropout(0.2, (None, 32)))\n",
    "model3.add(layers.Dense(1, activation=\"sigmoid\")) \n",
    "model3.compile(optimizer='adam',\n",
    "               loss=\"binary_crossentropy\",\n",
    "               metrics=['accuracy'])\n",
    "model3.build(input_shape=(None, shape))\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.9796 - accuracy: 0.6466 - val_loss: 0.7686 - val_accuracy: 0.6906\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1612 - accuracy: 0.9461 - val_loss: 0.7867 - val_accuracy: 0.7164\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1020 - accuracy: 0.9671 - val_loss: 0.8230 - val_accuracy: 0.7164\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb95dd66d0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), \n",
    "    batch_size=batch_size, epochs=20,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This isnt bad, but lets try to add a LSTM layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4\n",
    "* Adding a LSTM layer to model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5569, 5084)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1393, 5084)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reshape before I can use LSTM\n",
    "n_features = x_train.shape[1]\n",
    "train_rows = x_train.shape[0]\n",
    "test_rows = x_test.shape[0]\n",
    "x_train_array = x_train.to_numpy().reshape(train_rows, n_features, 1)\n",
    "x_test_array = x_test.to_numpy().reshape(test_rows, n_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = models.Sequential()\n",
    "model4.add(layers.Input(shape=(n_features,1)))\n",
    "model4.add(layers.Bidirectional(layers.LSTM(units=32)))\n",
    "model4.add(layers.Dense(32, activation=\"relu\"))\n",
    "model4.add(layers.Dropout(0.2, (None, 32)))\n",
    "model4.add(layers.Dense(1, activation=\"sigmoid\")) \n",
    "model4.compile(optimizer='adam',\n",
    "               loss=\"binary_crossentropy\",\n",
    "               metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 1224s 7s/step - loss: 0.6803 - accuracy: 0.5795 - val_loss: 0.6757 - val_accuracy: 0.5908\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 1227s 7s/step - loss: 0.6771 - accuracy: 0.5850 - val_loss: 0.6749 - val_accuracy: 0.6009\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 1191s 7s/step - loss: 0.6795 - accuracy: 0.5820 - val_loss: 0.6748 - val_accuracy: 0.5994\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 1150s 7s/step - loss: 0.6808 - accuracy: 0.5827 - val_loss: 0.6778 - val_accuracy: 0.6016\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 1131s 6s/step - loss: 0.6793 - accuracy: 0.5845 - val_loss: 0.6737 - val_accuracy: 0.6001\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 1148s 7s/step - loss: 0.6786 - accuracy: 0.5861 - val_loss: 0.6748 - val_accuracy: 0.6016\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 1202s 7s/step - loss: 0.6777 - accuracy: 0.5861 - val_loss: 0.6736 - val_accuracy: 0.6016\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 1203s 7s/step - loss: 0.6765 - accuracy: 0.5863 - val_loss: 0.6705 - val_accuracy: 0.6001\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 1229s 7s/step - loss: 0.6780 - accuracy: 0.5861 - val_loss: 0.6746 - val_accuracy: 0.6030\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 1178s 7s/step - loss: 0.6784 - accuracy: 0.5881 - val_loss: 0.6761 - val_accuracy: 0.6016\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feab86cf690>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(\n",
    "    [x_train_array], y_train, validation_data=([x_test_array],y_test),\n",
    "    batch_size=batch_size, epochs=20,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not good "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 5\n",
    "* Go back to original data and see if we can train it using bidirectional LSTM without crashing everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to split again since we are going back to pre-PCA data\n",
    "x_train,  x_test, y_train, y_test = train_test_split(dfSparse,dfTweets['target'],test_size = 0.2)\n",
    "# Reshape to fit the model\n",
    "n_features = x_train.shape[1]\n",
    "train_rows = x_train.shape[0]\n",
    "test_rows = x_test.shape[0]\n",
    "x_train_array = x_train.to_numpy().reshape(train_rows, n_features, 1)\n",
    "x_test_array = x_test.to_numpy().reshape(test_rows, n_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = models.Sequential()\n",
    "model5.add(layers.Input(shape=(n_features,1)))\n",
    "model5.add(layers.Bidirectional(layers.LSTM(units=32)))\n",
    "model5.add(layers.Dense(32, activation=\"relu\"))\n",
    "model5.add(layers.Dropout(0.2, (None, 32)))\n",
    "model5.add(layers.Dense(1, activation=\"sigmoid\")) \n",
    "model5.compile(optimizer='adam',\n",
    "               loss=\"binary_crossentropy\",\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "175/175 [==============================] - 4624s 26s/step - loss: 0.6797 - accuracy: 0.5886 - val_loss: 0.6780 - val_accuracy: 0.5894\n",
      "Epoch 2/40\n",
      "175/175 [==============================] - 4503s 26s/step - loss: 0.6788 - accuracy: 0.5886 - val_loss: 0.6771 - val_accuracy: 0.5894\n",
      "Epoch 3/40\n",
      "175/175 [==============================] - 4531s 26s/step - loss: 0.6788 - accuracy: 0.5886 - val_loss: 0.6771 - val_accuracy: 0.5894\n",
      "Epoch 4/40\n",
      "175/175 [==============================] - 4485s 26s/step - loss: 0.6779 - accuracy: 0.5886 - val_loss: 0.6780 - val_accuracy: 0.5894\n",
      "Epoch 5/40\n",
      "175/175 [==============================] - 4517s 26s/step - loss: 0.6786 - accuracy: 0.5886 - val_loss: 0.6771 - val_accuracy: 0.5894\n",
      "Epoch 6/40\n",
      "175/175 [==============================] - 4514s 26s/step - loss: 0.6782 - accuracy: 0.5886 - val_loss: 0.6771 - val_accuracy: 0.5894\n",
      "Epoch 7/40\n",
      "175/175 [==============================] - 4495s 26s/step - loss: 0.6781 - accuracy: 0.5886 - val_loss: 0.6771 - val_accuracy: 0.5894\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feabec3c4d0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='auto', patience=4, verbose=1)\n",
    "# Giving this one more patience to see if it breaks out of rut on early train\n",
    "# Hopefully it doesnt need all 40 epochs\n",
    "# ETA for epoch 1 started at 1:20, so I will check on this tomorrow\n",
    "model5.fit(\n",
    "    [x_train_array], y_train, validation_data=([x_test_array],y_test),\n",
    "    batch_size=batch_size, epochs=40,\n",
    "    callbacks=[es]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first successful model we tested was a shallow backpropagation network. \n",
    "* It had validation results around 70%\n",
    "* Our next attempt with a more robust network overtrained\n",
    "* It had good accuracy with training data but had poor validation\n",
    "* We added a dropout layer and tried PCA to fix some issues\n",
    "* That helped some but the simple model was still competative with this more complex model\n",
    "* Considering the difference in training time, the extra complexity was not worth it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Training Accuracy | Validation Accuracy |\n",
    "|-|-|-|\n",
    "| 1 | 0.9930 | 0.7609 | \n",
    "| 2 | 0.9776 | 0.6906 | \n",
    "| 3 | 0.9672 | 0.7164 |\n",
    "| 4 | 0.5881 | 0.6016 |\n",
    "| 5 | 0.5886 | 0.5894 |\n",
    "\n",
    "* Model 4 may have continued to improve but it met the early stop threshold after 10 epochs\n",
    "* It was improving very slowly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "* https://towardsdatascience.com/tf-idf-explained-and-python-sklearn-implementation-b020c5e83275\n",
    "* https://towardsdatascience.com/how-to-turn-text-into-features-478b57632e99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
